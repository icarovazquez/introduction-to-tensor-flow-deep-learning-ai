{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horses-Humans_Transfer-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icarovazquez/introduction-to-tensor-flow-deep-learning-ai/blob/master/Horses_Humans_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "0f9fd5cc-f857-4ba8-80c8-45de6845aaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-08 22:18:57--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  54.0MB/s    in 1.6s    \n",
            "\n",
            "2019-10-08 22:19:00 (54.0 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1008 22:19:00.884566 140429342189440 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "b82e3e7e-eb9c-4ca3-8c52-50ff798e0b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "7a46dc36-b732-4ddd-cdb5-539cde0e8e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1008 22:19:21.081542 140429342189440 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "dd19c1ac-309c-440b-a406-c2249fffd2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-08 22:19:25--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  49.7MB/s    in 2.9s    \n",
            "\n",
            "2019-10-08 22:19:28 (49.7 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-08 22:19:29--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-08 22:19:30 (112 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "5d7524b0-1abd-4d20-b9e6-662deb62e26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = train_horses_dir\n",
        "train_humans_fnames = train_humans_dir\n",
        "validation_horses_fnames = validation_horses_dir\n",
        "validation_humans_fnames = validation_humans_dir\n",
        "\n",
        "print(len(os.listdir(train_horses_fnames)))\n",
        "print(len(os.listdir(train_humans_fnames)))\n",
        "print(len(os.listdir(validation_horses_fnames)))\n",
        "print(len(os.listdir(validation_humans_fnames)))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "71fda91d-4563-42bd-f838-86850e6c962e"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
        "                                             rotation_range = 40,\n",
        "                                             width_shift_range = 0.2,\n",
        "                                             height_shift_range = 0.2,\n",
        "                                             shear_range = 0.2,\n",
        "                                             zoom_range = 0.2,\n",
        "                                             horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size= (150, 150)\n",
        "                                                   )     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size = 20,\n",
        "                                                         class_mode = 'binary',\n",
        "                                                         target_size = (150, 150)\n",
        "                                                        )\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b9672d2-f124-4b98-d731-1acdb5d94da1"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              steps_per_epoch = 100,\n",
        "                              epochs = 100, \n",
        "                              validation_steps = 50,\n",
        "                              verbose = 2,\n",
        "                              callbacks=[callbacks])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 30s - loss: 0.0739 - acc: 0.9767 - val_loss: 9.4858e-04 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0573 - acc: 0.9802 - val_loss: 0.0154 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 30s - loss: 0.0573 - acc: 0.9823 - val_loss: 0.1312 - val_acc: 0.9727\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0300 - acc: 0.9909 - val_loss: 0.2747 - val_acc: 0.9676\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0542 - acc: 0.9853 - val_loss: 0.2424 - val_acc: 0.9646\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0469 - acc: 0.9839 - val_loss: 0.3279 - val_acc: 0.9646\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0212 - acc: 0.9939 - val_loss: 0.1567 - val_acc: 0.9767\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0435 - acc: 0.9918 - val_loss: 0.3410 - val_acc: 0.9595\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.4750 - val_acc: 0.9615\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0237 - acc: 0.9925 - val_loss: 0.6169 - val_acc: 0.9626\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0235 - acc: 0.9954 - val_loss: 0.3528 - val_acc: 0.9676\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0177 - acc: 0.9924 - val_loss: 0.4118 - val_acc: 0.9595\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0389 - acc: 0.9894 - val_loss: 0.2447 - val_acc: 0.9686\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0158 - acc: 0.9954 - val_loss: 0.2677 - val_acc: 0.9636\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0363 - acc: 0.9924 - val_loss: 0.2880 - val_acc: 0.9656\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0205 - acc: 0.9944 - val_loss: 0.3629 - val_acc: 0.9605\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0223 - acc: 0.9935 - val_loss: 0.3905 - val_acc: 0.9646\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0215 - acc: 0.9934 - val_loss: 0.3964 - val_acc: 0.9636\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0113 - acc: 0.9965 - val_loss: 0.3523 - val_acc: 0.9646\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0201 - acc: 0.9934 - val_loss: 1.1351 - val_acc: 0.9413\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0183 - acc: 0.9929 - val_loss: 0.4302 - val_acc: 0.9686\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0441 - acc: 0.9883 - val_loss: 0.7645 - val_acc: 0.9443\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0146 - acc: 0.9965 - val_loss: 0.3917 - val_acc: 0.9646\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0056 - acc: 0.9980 - val_loss: 0.4701 - val_acc: 0.9595\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0131 - acc: 0.9959 - val_loss: 0.7704 - val_acc: 0.9484\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0318 - acc: 0.9944 - val_loss: 0.9512 - val_acc: 0.9443\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0106 - acc: 0.9959 - val_loss: 1.3149 - val_acc: 0.9423\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 30s - loss: 0.0341 - acc: 0.9945 - val_loss: 0.5893 - val_acc: 0.9494\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0157 - acc: 0.9965 - val_loss: 0.9870 - val_acc: 0.9423\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0174 - acc: 0.9975 - val_loss: 1.0842 - val_acc: 0.9433\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0134 - acc: 0.9964 - val_loss: 0.8413 - val_acc: 0.9453\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0076 - acc: 0.9965 - val_loss: 1.9774 - val_acc: 0.9180\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0035 - acc: 0.9975 - val_loss: 0.6891 - val_acc: 0.9575\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0085 - acc: 0.9970 - val_loss: 0.8297 - val_acc: 0.9453\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0208 - acc: 0.9959 - val_loss: 0.6073 - val_acc: 0.9565\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0154 - acc: 0.9965 - val_loss: 0.5600 - val_acc: 0.9575\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0271 - acc: 0.9949 - val_loss: 1.0046 - val_acc: 0.9464\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0027 - acc: 0.9990 - val_loss: 1.1603 - val_acc: 0.9403\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0124 - acc: 0.9965 - val_loss: 0.5954 - val_acc: 0.9524\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0247 - acc: 0.9939 - val_loss: 0.8627 - val_acc: 0.9484\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0106 - acc: 0.9975 - val_loss: 0.3113 - val_acc: 0.9767\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0157 - acc: 0.9954 - val_loss: 0.8014 - val_acc: 0.9464\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0081 - acc: 0.9959 - val_loss: 0.7994 - val_acc: 0.9443\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0178 - acc: 0.9980 - val_loss: 1.1981 - val_acc: 0.9413\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0079 - acc: 0.9985 - val_loss: 1.2047 - val_acc: 0.9403\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0087 - acc: 0.9980 - val_loss: 1.8288 - val_acc: 0.9160\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0167 - acc: 0.9955 - val_loss: 0.9201 - val_acc: 0.9474\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0219 - acc: 0.9964 - val_loss: 1.1068 - val_acc: 0.9413\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0156 - acc: 0.9965 - val_loss: 1.8030 - val_acc: 0.9180\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0324 - acc: 0.9904 - val_loss: 1.5242 - val_acc: 0.9383\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0113 - acc: 0.9959 - val_loss: 0.9082 - val_acc: 0.9453\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0201 - acc: 0.9954 - val_loss: 1.1608 - val_acc: 0.9393\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0049 - acc: 0.9985 - val_loss: 1.4868 - val_acc: 0.9393\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0090 - acc: 0.9975 - val_loss: 1.4446 - val_acc: 0.9393\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0164 - acc: 0.9965 - val_loss: 1.6429 - val_acc: 0.9291\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0200 - acc: 0.9944 - val_loss: 1.3988 - val_acc: 0.9342\n",
            "Epoch 57/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0255 - acc: 0.9955 - val_loss: 1.1136 - val_acc: 0.9403\n",
            "Epoch 58/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0049 - acc: 0.9985 - val_loss: 1.0419 - val_acc: 0.9403\n",
            "Epoch 59/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0157 - acc: 0.9964 - val_loss: 0.6568 - val_acc: 0.9636\n",
            "Epoch 60/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0082 - acc: 0.9975 - val_loss: 1.5966 - val_acc: 0.9393\n",
            "Epoch 61/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0102 - acc: 0.9980 - val_loss: 0.3697 - val_acc: 0.9808\n",
            "Epoch 62/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0099 - acc: 0.9980 - val_loss: 0.3522 - val_acc: 0.9808\n",
            "Epoch 63/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0087 - acc: 0.9975 - val_loss: 0.3743 - val_acc: 0.9777\n",
            "Epoch 64/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.6720 - val_acc: 0.9636\n",
            "Epoch 65/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0081 - acc: 0.9980 - val_loss: 1.1151 - val_acc: 0.9443\n",
            "Epoch 66/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0113 - acc: 0.9970 - val_loss: 1.1757 - val_acc: 0.9423\n",
            "Epoch 67/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0075 - acc: 0.9985 - val_loss: 0.7446 - val_acc: 0.9615\n",
            "Epoch 68/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0161 - acc: 0.9970 - val_loss: 0.7658 - val_acc: 0.9626\n",
            "Epoch 69/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0069 - acc: 0.9980 - val_loss: 1.0906 - val_acc: 0.9413\n",
            "Epoch 70/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0075 - acc: 0.9980 - val_loss: 1.0930 - val_acc: 0.9393\n",
            "Epoch 71/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0290 - acc: 0.9970 - val_loss: 0.7520 - val_acc: 0.9646\n",
            "Epoch 72/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0112 - acc: 0.9980 - val_loss: 1.0549 - val_acc: 0.9504\n",
            "Epoch 73/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0077 - acc: 0.9990 - val_loss: 1.0253 - val_acc: 0.9443\n",
            "Epoch 74/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0101 - acc: 0.9970 - val_loss: 1.7247 - val_acc: 0.9352\n",
            "Epoch 75/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0094 - acc: 0.9965 - val_loss: 1.2534 - val_acc: 0.9413\n",
            "Epoch 76/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0115 - acc: 0.9970 - val_loss: 0.9962 - val_acc: 0.9494\n",
            "Epoch 77/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0308 - acc: 0.9954 - val_loss: 0.9273 - val_acc: 0.9524\n",
            "Epoch 78/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0121 - acc: 0.9975 - val_loss: 1.0776 - val_acc: 0.9494\n",
            "Epoch 79/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0042 - acc: 0.9990 - val_loss: 1.6557 - val_acc: 0.9413\n",
            "Epoch 80/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0223 - acc: 0.9939 - val_loss: 0.9920 - val_acc: 0.9565\n",
            "Epoch 81/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0106 - acc: 0.9985 - val_loss: 1.0948 - val_acc: 0.9464\n",
            "Epoch 82/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0128 - acc: 0.9975 - val_loss: 1.7924 - val_acc: 0.9352\n",
            "Epoch 83/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0037 - acc: 0.9990 - val_loss: 1.1883 - val_acc: 0.9464\n",
            "Epoch 84/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0047 - acc: 0.9990 - val_loss: 0.9466 - val_acc: 0.9646\n",
            "Epoch 85/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0096 - acc: 0.9975 - val_loss: 1.4348 - val_acc: 0.9433\n",
            "Epoch 86/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0138 - acc: 0.9975 - val_loss: 1.5808 - val_acc: 0.9403\n",
            "Epoch 87/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0113 - acc: 0.9975 - val_loss: 1.7486 - val_acc: 0.9372\n",
            "Epoch 88/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0169 - acc: 0.9954 - val_loss: 1.5320 - val_acc: 0.9393\n",
            "Epoch 89/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0035 - acc: 0.9985 - val_loss: 1.6669 - val_acc: 0.9352\n",
            "Epoch 90/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0076 - acc: 0.9980 - val_loss: 1.4229 - val_acc: 0.9453\n",
            "Epoch 91/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0252 - acc: 0.9959 - val_loss: 1.7828 - val_acc: 0.9362\n",
            "Epoch 92/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0114 - acc: 0.9959 - val_loss: 1.5138 - val_acc: 0.9413\n",
            "Epoch 93/100\n",
            "Epoch 1/100\n",
            "100/100 - 30s - loss: 0.0129 - acc: 0.9975 - val_loss: 1.0558 - val_acc: 0.9504\n",
            "Epoch 94/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0065 - acc: 0.9985 - val_loss: 1.3509 - val_acc: 0.9423\n",
            "Epoch 95/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0041 - acc: 0.9975 - val_loss: 1.3820 - val_acc: 0.9423\n",
            "Epoch 96/100\n",
            "Epoch 1/100\n",
            "100/100 - 29s - loss: 0.0093 - acc: 0.9975 - val_loss: 1.0443 - val_acc: 0.9514\n",
            "Epoch 97/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0045 - acc: 0.9980 - val_loss: 0.7178 - val_acc: 0.9595\n",
            "Epoch 98/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0241 - acc: 0.9965 - val_loss: 0.5869 - val_acc: 0.9676\n",
            "Epoch 99/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0293 - acc: 0.9969 - val_loss: 1.1965 - val_acc: 0.9453\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.0188 - acc: 0.9975 - val_loss: 0.8731 - val_acc: 0.9595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "725b73b0-de06-4f0a-8e9f-098c4872d43a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NdeC_DAfs-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}